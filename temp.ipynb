{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adj = pd.read_csv('adj.csv')\n",
    "data_adv = pd.read_csv('adv.csv')\n",
    "data_noun = pd.read_csv('noun.csv')\n",
    "data_verb = pd.read_csv('verb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_csv(data):\n",
    "    pbi_words_synonym = []\n",
    "    for i in range (0,len(data)):\n",
    "        try :\n",
    "            pbi_words_synonym.append(data['punjabi'][i].split())\n",
    "        except:\n",
    "            pbi_words_synonym.append('NaN')\n",
    "\n",
    "    eng2pun = {}\n",
    "    row,_ = data.shape\n",
    "    for i in range(row-1):\n",
    "        eng2pun[data['english'].iloc[i]] = pbi_words_synonym[i]\n",
    "    return eng2pun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_multiphrase(my_dict):\n",
    "    ## removing multiphase punjabi words::\n",
    "    for eng,pbi in my_dict.items():\n",
    "        for i in pbi:\n",
    "            if i.find(\"_\") != -1:\n",
    "                pbi.remove(i)\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we will change our files that is data_adj, data_adv, data_noun and data_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluating csv to dict\n",
    "noun_dict = eval_csv(data_noun)\n",
    "noun_dict = removing_multiphrase(noun_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing english and punjbai words count from our dataset\n",
    "f = open('eng.json')\n",
    "eng_count = json.load(f)\n",
    "\n",
    "f = open('punjabi.json')\n",
    "pbi_count = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_top1000(data_dict,eng_count):\n",
    "    ## making count of words from our dataset\n",
    "    file_count={}\n",
    "    for input in data_dict:\n",
    "        for key,value in eng_count.items():\n",
    "            if key == input:\n",
    "                file_count[key]=value\n",
    "\n",
    "    #descending order\n",
    "    counts = dict(sorted(file_count.items(), key=lambda x:x[1],reverse=True))\n",
    "\n",
    "    #filtering top 1000\n",
    "    my_dict = {}\n",
    "    cnt = 0 \n",
    "    for key,value in counts.items():\n",
    "        if cnt >= 1000:\n",
    "            break\n",
    "        my_dict[key]=value\n",
    "        cnt+=1\n",
    "\n",
    "    # pushing the filtered dict \n",
    "    filtered_dict={}\n",
    "    for inp,value in data_dict.items():\n",
    "        if inp in my_dict:\n",
    "            filtered_dict[inp]=value\n",
    "    return filtered_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_pbi_words(filtered_dict,pbi_count):\n",
    "    temp_2={}\n",
    "    #now filtering the punjabi words by criterias that the most occured word from the list will be taken \n",
    "    # counting the frequency of each punjabi word (from our dataset) and considering the maximum one.\n",
    "    for key,pbi_list in filtered_dict.items():\n",
    "        maxi = 0\n",
    "        for i in pbi_list:\n",
    "            if i in pbi_count.keys():\n",
    "                maxi = max(maxi, pbi_count[i])\n",
    "        ## this for loop will return the frequency of maximum word occured out of all\n",
    "        for i in pbi_list:\n",
    "            if i in pbi_count.keys():\n",
    "                pbi_count[i] == maxi\n",
    "                temp_2[key] = i\n",
    "        ## this loop will find the word with max frequency and pushing back to new dict\n",
    "    return temp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = filtering_top1000(noun_dict,eng_count)\n",
    "temp = filtering_pbi_words(temp,pbi_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noun_final.json', 'w') as f:\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for eng,pbi_list in temp.items():\n",
    "#     count = 0\n",
    "#     pbi_count_dict={}\n",
    "#     for i in range (0,len(pbi_list)):\n",
    "#         if pbi_list[i] in pbi_count:\n",
    "#             pbi_count_dict[pbi_list[i]] = pbi_count[pbi_list[i]]\n",
    "#         else:\n",
    "#             pbi_count_dict[pbi_list[i]]=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
